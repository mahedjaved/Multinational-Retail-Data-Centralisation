{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install SQLAlchemy\n",
    "# !pip install psycopg2\n",
    "# !pip install pandas\n",
    "# !pip install PyYAML\n",
    "# !pip install tabula-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, MetaData, Table, select\n",
    "from dateutil.parser import parse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "import yaml\n",
    "import re\n",
    "import tabula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test code for Psycopg2\n",
    "# conn = psycopg2.connect(\n",
    "#     host=ENDPOINT,\n",
    "#     port=PORT,\n",
    "#     database=DATABASE,\n",
    "#     user=USER,\n",
    "#     password=PASSWORD\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_file_path = '../db_creds.yaml'\n",
    "\n",
    "# Read the YAML file and store its contents in a Python data structure (dictionary)\n",
    "with open(yaml_file_path, 'r') as file:\n",
    "    yaml_data = yaml.safe_load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# credentials\n",
    "DATABASE_TYPE = 'postgresql'\n",
    "# DBAPI = 'psycopg2'\n",
    "ENDPOINT = yaml_data['RDS_HOST']\n",
    "USER = yaml_data['RDS_USER']\n",
    "PASSWORD = yaml_data['RDS_PASSWORD']\n",
    "PORT = yaml_data['RDS_PORT']\n",
    "DATABASE = yaml_data['RDS_DATABASE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup sql engine and connect\n",
    "sql_engine = create_engine(f\"{DATABASE_TYPE}://{USER}:{PASSWORD}@{ENDPOINT}:{PORT}/{DATABASE}\")\n",
    "sql_connection = sql_engine.connect()\n",
    "\n",
    "# metadata, holds collection of table info, their data types, schema names etc., obtained from here : https://docs.sqlalchemy.org/en/20/core/metadata.html\n",
    "# pros of MetaData() includes thread safety -> meaning it can handle concurrent tasks from multiple thread (computationally efficient when multiple threads need access to same resource)\n",
    "metadata = MetaData()\n",
    "metadata.reflect(sql_engine)\n",
    "table_names = metadata.tables.keys()\n",
    "\n",
    "# reflect allows us\n",
    "names_ = list(table_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read table\n",
    "users_table = sql_connection.execute(select(Table('legacy_users', metadata, autoload=True, autoload_with=sql_engine)))\n",
    "headers = users_table.keys()\n",
    "users_df = pd.DataFrame(users_table.fetchall(), columns=headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3 -- Users Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = 'legacy_users'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_alphanumeric(in_str):\n",
    "    \"\"\"\n",
    "    @desc: function to check if the column has alphanumeric entries\n",
    "    \"\"\"\n",
    "    return bool(re.fullmatch(r'^[a-zA-Z0-9_]*$', in_str))\n",
    "\n",
    "def has_yyyy_mm_dd_format(in_str):\n",
    "    \"\"\"\n",
    "    @desc: function to decide if the a column of a data has date format yyyy-mm-dd\n",
    "    \"\"\"\n",
    "    return bool(re.fullmatch(r'\\d{4}-\\d{2}-\\d{2}', in_str))\n",
    "\n",
    "def convert_date_to_yyyy_mm_dd(in_column : pd.core.series.Series):\n",
    "    \"\"\"\n",
    "    @desc: function to set the date column with date format yyyy-mm-dd\n",
    "    \"\"\"\n",
    "    in_column = in_column.apply(parse)\n",
    "    in_column = pd.to_datetime(in_column, infer_datetime_format=True, errors='coerce')\n",
    "    \n",
    "    return in_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[usrmsg] No NULLs or NaNs found in legacy_users\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_1/8dh8hgjn3573dq6g_b03d7x00000gn/T/ipykernel_883/3295942194.py:18: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  in_column = pd.to_datetime(in_column, infer_datetime_format=True, errors='coerce')\n",
      "/var/folders/_1/8dh8hgjn3573dq6g_b03d7x00000gn/T/ipykernel_883/3295942194.py:18: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  in_column = pd.to_datetime(in_column, infer_datetime_format=True, errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "# check for nulls or NaNs, alternative is np.unique(users_df.isnull()), or just use df.info()\n",
    "if users_df.isnull().sum().sum() and users_df.isna().sum().sum():\n",
    "    raise f\"The database : {table_name}, has total {users_df.isnull().sum().sum()} NULL values and {users_df.isna().sum().sum()} NaN values\"\n",
    "else:\n",
    "    print(f\"[usrmsg] No NULLs or NaNs found in {table_name}\")\n",
    "\n",
    "users_df_processed = users_df[~users_df.apply(lambda row: row.astype(str).str.contains('NULL').any(), axis=1)]\n",
    "\n",
    "# check for data types \n",
    "#   -1) always begin with dropping duplicates and storing as a seperate file\n",
    "users_df_processed = users_df_processed.drop_duplicates()\n",
    "#   -2) set all columns except index to be of string format\n",
    "str_convert_dict = {col: 'string' for col in users_df_processed.columns if col not in ['index']}\n",
    "users_df_processed = users_df_processed.astype(str_convert_dict)\n",
    "#   -3) remove all entries that are pure alphanumeric\n",
    "users_df_processed = users_df_processed[~users_df_processed['email_address'].apply(is_alphanumeric)]\n",
    "#   -4) DoB and join_date should be datetime format and of type yyyy-mm-dd\n",
    "users_df_processed['date_of_birth'] = convert_date_to_yyyy_mm_dd(users_df_processed['date_of_birth'])\n",
    "users_df_processed['join_date'] = convert_date_to_yyyy_mm_dd(users_df_processed['join_date'])\n",
    "#   -5) convert all 'GGB' country code to 'GB'\n",
    "users_df_processed['country_code'] = users_df_processed['country_code'].str.replace('GGB', 'GB', regex=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>company</th>\n",
       "      <th>email_address</th>\n",
       "      <th>address</th>\n",
       "      <th>country</th>\n",
       "      <th>country_code</th>\n",
       "      <th>phone_number</th>\n",
       "      <th>join_date</th>\n",
       "      <th>user_uuid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Sigfried</td>\n",
       "      <td>Noack</td>\n",
       "      <td>1990-09-30</td>\n",
       "      <td>Heydrich Junitz KG</td>\n",
       "      <td>rudi79@winkler.de</td>\n",
       "      <td>Zimmerstr. 1/0\n",
       "59015 Gie√üen</td>\n",
       "      <td>Germany</td>\n",
       "      <td>DE</td>\n",
       "      <td>+49(0) 047905356</td>\n",
       "      <td>2018-10-10</td>\n",
       "      <td>93caf182-e4e9-4c6e-bebb-60a1a9dcf9b8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Guy</td>\n",
       "      <td>Allen</td>\n",
       "      <td>1940-12-01</td>\n",
       "      <td>Fox Ltd</td>\n",
       "      <td>rhodesclifford@henderson.com</td>\n",
       "      <td>Studio 22a\n",
       "Lynne terrace\n",
       "McCarthymouth\n",
       "TF0 9GH</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>GB</td>\n",
       "      <td>(0161) 496 0674</td>\n",
       "      <td>2001-12-20</td>\n",
       "      <td>8fe96c3a-d62d-4eb5-b313-cf12d9126a49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Harry</td>\n",
       "      <td>Lawrence</td>\n",
       "      <td>1995-08-02</td>\n",
       "      <td>Johnson, Jones and Harris</td>\n",
       "      <td>glen98@bryant-marshall.co.uk</td>\n",
       "      <td>92 Ann drive\n",
       "Joanborough\n",
       "SK0 6LR</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>GB</td>\n",
       "      <td>+44(0)121 4960340</td>\n",
       "      <td>2016-12-16</td>\n",
       "      <td>fc461df4-b919-48b2-909e-55c95a03fe6b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Darren</td>\n",
       "      <td>Hussain</td>\n",
       "      <td>1972-09-23</td>\n",
       "      <td>Wheeler LLC</td>\n",
       "      <td>daniellebryan@thompson.org</td>\n",
       "      <td>19 Robinson meadow\n",
       "New Tracy\n",
       "W22 2QG</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>GB</td>\n",
       "      <td>(0306) 999 0871</td>\n",
       "      <td>2004-02-23</td>\n",
       "      <td>6104719f-ef14-4b09-bf04-fb0c4620acb0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Garry</td>\n",
       "      <td>Stone</td>\n",
       "      <td>1952-12-20</td>\n",
       "      <td>Warner Inc</td>\n",
       "      <td>billy14@long-warren.com</td>\n",
       "      <td>3 White pass\n",
       "Hunterborough\n",
       "NN96 4UE</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>GB</td>\n",
       "      <td>0121 496 0225</td>\n",
       "      <td>2006-09-01</td>\n",
       "      <td>9523a6d3-b2dd-4670-a51a-36aebc89f579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index first_name last_name date_of_birth                    company  \\\n",
       "0      0   Sigfried     Noack    1990-09-30         Heydrich Junitz KG   \n",
       "1      1        Guy     Allen    1940-12-01                    Fox Ltd   \n",
       "2      2      Harry  Lawrence    1995-08-02  Johnson, Jones and Harris   \n",
       "3      3     Darren   Hussain    1972-09-23                Wheeler LLC   \n",
       "4      4      Garry     Stone    1952-12-20                 Warner Inc   \n",
       "\n",
       "                  email_address  \\\n",
       "0             rudi79@winkler.de   \n",
       "1  rhodesclifford@henderson.com   \n",
       "2  glen98@bryant-marshall.co.uk   \n",
       "3    daniellebryan@thompson.org   \n",
       "4       billy14@long-warren.com   \n",
       "\n",
       "                                          address         country  \\\n",
       "0                     Zimmerstr. 1/0\n",
       "59015 Gie√üen         Germany   \n",
       "1  Studio 22a\n",
       "Lynne terrace\n",
       "McCarthymouth\n",
       "TF0 9GH  United Kingdom   \n",
       "2                92 Ann drive\n",
       "Joanborough\n",
       "SK0 6LR  United Kingdom   \n",
       "3            19 Robinson meadow\n",
       "New Tracy\n",
       "W22 2QG  United Kingdom   \n",
       "4             3 White pass\n",
       "Hunterborough\n",
       "NN96 4UE  United Kingdom   \n",
       "\n",
       "  country_code       phone_number  join_date  \\\n",
       "0           DE   +49(0) 047905356 2018-10-10   \n",
       "1           GB    (0161) 496 0674 2001-12-20   \n",
       "2           GB  +44(0)121 4960340 2016-12-16   \n",
       "3           GB    (0306) 999 0871 2004-02-23   \n",
       "4           GB      0121 496 0225 2006-09-01   \n",
       "\n",
       "                              user_uuid  \n",
       "0  93caf182-e4e9-4c6e-bebb-60a1a9dcf9b8  \n",
       "1  8fe96c3a-d62d-4eb5-b313-cf12d9126a49  \n",
       "2  fc461df4-b919-48b2-909e-55c95a03fe6b  \n",
       "3  6104719f-ef14-4b09-bf04-fb0c4620acb0  \n",
       "4  9523a6d3-b2dd-4670-a51a-36aebc89f579  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_df_processed.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_file_path = '../local_db_creds.yaml'\n",
    "\n",
    "# Read the YAML file and store its contents in a Python data structure (dictionary)\n",
    "with open(yaml_file_path, 'r') as file:\n",
    "    yaml_data = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# credentials\n",
    "DATABASE_TYPE = 'postgresql+psycopg2'\n",
    "ENDPOINT = yaml_data['LOCAL_HOST']\n",
    "USER = yaml_data['LOCAL_USER']\n",
    "PASSWORD = yaml_data['LOCAL_PASSWORD']\n",
    "PORT = yaml_data['LOCAL_PORT']\n",
    "DATABASE = yaml_data['LOCAL_DATABASE']\n",
    "\n",
    "engine = create_engine(f\"{DATABASE_TYPE}://{USER}:{PASSWORD}@{ENDPOINT}:{PORT}/{DATABASE}\")\n",
    "connection = engine.connect()\n",
    "users_df_processed.to_sql(\"dim_users\", engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4 -- Card Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read table\n",
    "users_table = sql_connection.execute(select(Table('legacy_users', metadata, autoload=True, autoload_with=sql_engine)))\n",
    "headers = users_table.keys()\n",
    "users_df = pd.DataFrame(users_table.fetchall(), columns=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(users_df_processed.iloc[1996], users_df_processed.iloc[1046], users_df_processed.iloc[866])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the date of the column has the format yyyy-mm-dd\n",
    "# incorrect_date_format_df = filtered_alphnum_df[~filtered_alphnum_df['date_of_birth'].apply(has_yyyy_mm_dd_format)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def null_n_nans_pass(df_):\n",
    "    \"\"\"\n",
    "    @desc: this function checks if the input dataframe has any NaNs or Nulls\n",
    "    \"\"\"\n",
    "    if df_.isnull().sum().sum() and df_.isna().sum().sum():\n",
    "        raise f\"The database : {table_name}, has total {df_.isnull().sum().sum()} NULL values and {df_.isna().sum().sum()} NaN values\"\n",
    "    else:\n",
    "        print(f\"[usrmsg] No NULLs or NaNs found in {table_name}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "airdmp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
